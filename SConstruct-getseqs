"""
Project template for 454 pplacer pipeline.
"""

import re
import os
import sys
import datetime
import ConfigParser
import csv
from os import path, environ

from SCons.Script import ARGUMENTS, Variables, Decider, \
    PathVariable, Flatten, Depends, Alias, Help, BoolVariable

# requirements installed in the virtualenv
from bioscons.fileutils import Targets
from bioscons.slurm import SlurmEnvironment

thisdir = path.basename(os.getcwd())

########################################################################
########################  input data  ##################################
########################################################################

settings = 'settings.conf'
if not path.exists(settings):
    sys.exit('\nCannot find "{}" '
             '- make a copy of one of settings*.conf and update as necessary'.format(settings))

conf = ConfigParser.SafeConfigParser(allow_no_value=True)
conf.read(settings)

venv = conf.get('input', 'virtualenv') or thisdir + '-env'

rdp = conf.get('input', 'rdp')
blast_db = path.join(rdp, 'blast')
blast_info = path.join(rdp, 'seq_info.csv')
blast_taxonomy = path.join(rdp, 'taxonomy.csv')

refpkg = conf.get('input', 'refpkg')

datadir = conf.get('input', 'datadir')
seqs = conf.get('input', 'seqs')
seq_info = conf.get('input', 'seq_info')
labels = conf.get('input', 'labels')
weights = conf.get('input', 'weights')

transfer_dir = conf.get('output', 'transfer_dir')
_timestamp = datetime.date.strftime(datetime.date.today(), '%Y-%m-%d')

########################################################################
#########################  end input data  #############################
########################################################################

# check timestamps before calculating md5 checksums
Decider('MD5-timestamp')

# declare variables for the environment
vars = Variables(None, ARGUMENTS)

vars.Add(BoolVariable('mock', 'Run pipeline with a small subset of input seqs', False))
vars.Add(BoolVariable('use_cluster', 'Dispatch jobs to cluster', True))
vars.Add(PathVariable('out', 'Path to output directory',
                      'output-getseqs', PathVariable.PathIsDirCreate))
vars.Add('nproc', 'Number of concurrent processes', default=12)

if transfer_dir:
    vars.Add('transfer_to',
             'Target directory for transferred data (using "transfer" target)',
             default=path.join(transfer_dir, '{}-{}'.format(_timestamp, thisdir)))
vars.Add(PathVariable('refpkg', 'Reference package', refpkg, PathVariable))

# Provides access to options prior to instantiation of env object
# below; it's better to access variables through the env object.
varargs = dict({opt.key: opt.default for opt in vars.options}, **vars.args)
truevals = {True, 'yes', 'y', 'True', 'true', 't'}
mock = varargs['mock'] in truevals
nproc = varargs['nproc']
use_cluster = varargs['use_cluster'] in truevals
refpkg = varargs['refpkg']

# Configure a virtualenv and environment
if not path.exists(venv):
    sys.exit('Please specify a virtualenv in settings.conf or '
             'create one using \'bin/bootstrap.sh\'.')
elif not ('VIRTUAL_ENV' in environ and \
        environ['VIRTUAL_ENV'].endswith(path.basename(venv))):
    sys.exit('--> run \nsource {}/bin/activate'.format(venv))

# Explicitly define PATH, giving preference to local executables; it's
# best to use absolute paths for non-local executables rather than add
# paths here to avoid accidental introduction of external
# dependencies.
env = SlurmEnvironment(
    ENV = dict(
        os.environ,
        PATH=':'.join(['bin',
                       path.join(venv, 'bin'),
                       '/home/matsengrp/local/bin',
                       '/usr/local/bin', '/usr/bin', '/bin']),
        SLURM_ACCOUNT='fredricks_d'),
    variables = vars,
    use_cluster=use_cluster,
    shell='bash'
)

# store file signatures in a separate .sconsign file in each
# directory; see http://www.scons.org/doc/HTML/scons-user/a11726.html
env.SConsignFile(None)
Help(vars.GenerateHelpText(env))
targets = Targets()

# start analysis

with open('data/get_seqs.csv') as f:
    taxa = list(csv.DictReader(f))

for_transfer = []
for row in taxa:
    e = env.Clone()
    tax_name = row['tax_name']
    safe_name = re.sub(r'[^a-zA-Z0-9]+', '_', tax_name)
    e['safe_name'] = safe_name
    e['out'] = e.subst('$out/$safe_name')

    centroids = e.Command(
        target='$out/${safe_name}.centroids.fasta',
        source=['output/placements.db', 'output/dedup.fasta', 'output/dedup_info.csv'],
        action=('getseqs.py ${SOURCES[:2]} '
                '--weights ${SOURCES[2]} '
                '--uc-id 0.985 '
                '--min-weight 10 '
                '--tax-name "%s" -o $TARGET') % (tax_name,)
    )

    alignments = e.Command(
        target='$out/${safe_name}.centroids.aln.fasta',
        source=centroids,
        action=('muscle -quiet -seqtype dna -in $SOURCE -out $TARGET')
        )

    tree = e.Command(
        target='$out/${safe_name}.centroids.tre',
        source=alignments,
        action=('FastTree -gtr -nt $SOURCE > $TARGET')
    )

    for_transfer.extend([centroids, alignments, tree])
    targets.update(locals().values())

# copy a subset of the results elsewhere
transfer = env.Local(
    target = '$transfer_to/project_status.txt',
    source = for_transfer,
    action = (
        'git diff-index --quiet HEAD || '
        'echo "error: there are uncommitted changes" && '
        'mkdir -p $transfer_to && '
        '(pwd && git --no-pager log -n1) > $TARGET && '
        'cp $SOURCES $transfer_to '
    )
)

Alias('transfer', transfer)

# end analysis
targets.update(locals().values())

# identify extraneous files
targets.show_extras(env['out'])
