"""
Project template for 454 pplacer pipeline.
"""

import os
import sys
import datetime
import subprocess

from os import path, environ

from SCons.Script import ARGUMENTS, Variables, Decider, Environment, \
    PathVariable, Flatten, Depends, Alias, Help

########################################################################
########################  input data  ##################################
########################################################################

refpkg = '/media/lvdata2/ion_cfstudy/cf_refset/cf.named.1.1.infernal1.1.refpkg'

ref_sto = path.join(refpkg, 'alignment.sto')
cmfile = path.join(refpkg, 'bacteria16S_508_mod5_v1.1.cm')

datadir = '/media/lvdata2/ion_cfstudy/ion_pipeline/output-20131120-10k'
data_db = path.join(datadir, 'classification.db')
#filtered = path.join(datadir, 'denoised_primers.fasta')
#seq_info = path.join(datadir, 'denoised_map_primers.csv')
#labels = path.join(datadir, 'labels_primers.csv')

_timestamp = datetime.date.strftime(datetime.date.today(), '%Y-%m-%d')
transfer_dir = '/media/lvdata2/ion_cfstudy'

########################################################################
#########################  end input data  #############################
########################################################################

# check timestamps before calculating md5 checksums
Decider('MD5-timestamp')

# declare variables for the environment
thisdir = path.basename(os.getcwd())
vars = Variables(None, ARGUMENTS)

vars.Add(PathVariable('datadir',
                      'Path to input data directory',
                      datadir,
                      PathVariable.PathAccept))

vars.Add(PathVariable('out', 'Path to output directory',
                      'output', PathVariable.PathIsDirCreate))

vars.Add('nproc',
         'Number of concurrent processes',
         default=12)

vars.Add('transfer_to',
         'Target directory for transferred data (using "transfer" target)',
         default=path.join(transfer_dir, '{}-{}'.format(_timestamp, thisdir)))

vars.Add(PathVariable('virtualenv',
                      'Location of virtualenv',
                      '../ion_cfstudy-env',
                      PathVariable.PathAccept))

# Provides access to options prior to instantiation of env object
# below; it's better to access variables through the env object.
varargs = dict({opt.key: opt.default for opt in vars.options}, **vars.args)
venv = varargs['virtualenv']
nproc = varargs['nproc']

# Configure a virtualenv and environment
if not path.exists(venv):
    sys.exit('--> run \nbin/bootstrap.sh')
elif not ('VIRTUAL_ENV' in environ
        and environ['VIRTUAL_ENV'].endswith(path.basename(venv))):
    sys.exit('--> run \nsource {}/bin/activate'.format(venv))

# requirements installed in the virtualenv
from bioscons.fileutils import Targets

# Explicitly define PATH, giving preference to local executables; it's
# best to use absolute paths for non-local executables rather than add
# paths here to avoid accidental introduction of external
# dependencies.
env = Environment(
    ENV = dict(
        os.environ,
        PATH=':'.join([
            'bin',
            path.join(venv, 'bin'),
            # '/home/nhoffman/local/bin',
            # '/app/bin',
            # '/home/matsengrp/local/bin',
            '/usr/local/bin', '/usr/bin', '/bin'])),
    variables = vars,
    SHELL='bash'
)

Help(vars.GenerateHelpText(env))

targets = Targets()

# We need a list of specimens to define targets, so get a list and
# save results in $specimens. Note that specimen names are assumed
# to have no spaces or characters that should not be in a filename.
# TODO: make specimen names safe for filesystem
env['specimens'] = env.subst('$out/specimens.txt')
if not path.exists(env.subst('$specimens')):
    cmd = env.subst('mkdir -p $out && find $datadir -name denoised.fasta | grep x > $specimens')
    print cmd
    subprocess.check_call(cmd, shell=True)

with open(env.subst('$specimens')) as f:
    specimens = f.read().split()

seq_info = env.Command(
    target = '$out/specimen_map.csv',
    source = None,
    action = 'find $datadir -name denoised_map.csv.bz2 | '
             'grep x | '
             'xargs bzcat > $TARGET'
    )

weights = env.Command(
    target = '$out/weights.csv',
    source = None,
    action = ('find $datadir -name weights.csv.bz2 | '
              'grep x | '
              """xargs bzcat | awk -F"," '{print $1","$1","$2}' > $TARGET""")
    )

"""
TODO:
Need to ignore empty fasta files or else cmalign complains.

Would be best to have file paths in the ion_pipeline/output/classifications.db
for all the files.  Then a simple sql query could be used
to put all this stuff together.
"""

dedup_placefiles = []
for specimen in specimens:
    # skip empty input files
    if os.stat(specimen).st_size < 1:
        continue

    e = env.Clone()
    e['out'] = path.join(env['out'], specimen.split('/')[6])

    merged = e.Command(
        target = ['$out/merged.fasta.gz', '$out/cmalign_scores.txt'],
        source = [refpkg, specimen],
        action = 'refpkg_align $SOURCES $TARGETS'
    )

    dedup_jplace, = e.Command(
        target = '$out/dedup.jplace',
        source = [refpkg, merged],
        action=('pplacer -p --inform-prior --prior-lower 0.01 --map-identity '
                '-c ${SOURCES[0]} -o $TARGET -j $nproc ${SOURCES[1]}'),
    )

    dedup_placefiles.append(dedup_jplace)

    targets.update(locals().values())

# concatenate unaligend input sequences; required for hybrid
# classifier
allspecimens_fa, = env.Command(
    target='$out/allspecimens.fasta.gz',
    source=specimens,
    action='cat $SOURCES | gzip > $TARGET'
    )

# concatenate placefiles
dedup_jplace_concat, = env.Command(
    target = '$out/dedup.jplace.gz',
    source = dedup_placefiles,
    action = 'guppy mft -o $TARGET $SOURCES'
    )

# reduplicate
redup_jplace_concat, = env.Command(
    target = '$out/redup.jplace.gz',
    source = [weights, dedup_jplace_concat],
    action = 'guppy redup -m -o $TARGET -d ${SOURCES[0]} ${SOURCES[1]}')

# length pca
lpca_pfx = 'cf_named'
proj, trans, xml = env.Command(
    target=['$out/lpca/{}.{}'.format(lpca_pfx, sfx) for sfx in ['proj', 'trans', 'xml']],
    source=[redup_jplace_concat, seq_info, refpkg],
    action=('mkdir -p $out/lpca && '
            'guppy lpca ${SOURCES[0]}:${SOURCES[1]} -c ${SOURCES[2]} '
            '--out-dir $out/lpca --prefix %s') % lpca_pfx
    )

print proj, trans, xml

# classify. --no-pre-mask is required for unaligned input sequences
classify_db, = env.Command(
    target = '$out/placements.db',
    source = [redup_jplace_concat, refpkg, allspecimens_fa],
    action = ('rppr prep_db -c ${SOURCES[1]} --sqlite $TARGET && '
              'guppy classify --pp --classifier hybrid2 --no-pre-mask -j ${nproc} '
              '${SOURCES[0]} '
              '-c ${SOURCES[1]} '
              '--nbc-sequences ${SOURCES[2]} '
              '--sqlite $TARGET && '
              'multiclass_concat.py $TARGET')
)

# perform classification at each major rank
for rank in ['phylum', 'class', 'order', 'family', 'genus', 'species']:
    e = env.Clone()
    e['rank'] = rank
    by_taxon, by_specimen, tallies_wide = e.Command(
        target=['$out/by_taxon.${rank}.csv', '$out/by_specimen.${rank}.csv',
                '$out/tallies_wide.${rank}.csv'],
        source=Flatten([classify_db, seq_info]),
        action=('classif_table.py ${SOURCES[0]} '
                '--specimen-map ${SOURCES[1]} '
                '${TARGETS[0]} '
                '--by-specimen ${TARGETS[1]} '
                '--tallies-wide ${TARGETS[2]} '
                '--rank ${rank}'))
    targets.update(locals().values())


#     decorated_groupbyspecimen, = env.Command(
#         target='$out/decoratedGroupBySpecimen.${rank}.csv',
#         source=[groupbyspecimen, labels],
#         action='csvjoin $SOURCES -c specimen >$TARGET')

#     for_transfer.extend([bytaxon, byspecimen, groupbyspecimen,
#                          decorated_groupbyspecimen])

# # save some info about executables
# version_info, = env.Command(
#     target='$out/version_info.txt',
#     source=None,
#     action='version_info.sh > $TARGET'
# )
# Depends(version_info, ['bin/version_info.sh', for_transfer])
# for_transfer.append(version_info)

# # copy a subset of the results elsewhere
# transfer = env.Command(
#     target = '$transfer_to/project_status.txt',
#     source = for_transfer,
#     action = (
#         'git diff-index --quiet HEAD || '
#         'echo "error: there are uncommitted changes" && '
#         'mkdir -p %(transfer_to)s && '
#         '(pwd && git --no-pager log -n1) > $TARGET && '
#         'cp $SOURCES $transfer_to '
#     )
# )

# Alias('transfer', transfer)

# end analysis
targets.update(locals().values())

# identify extraneous files
targets.show_extras(env['out'])
