"""
Provide details of classification results for each SV

usage::

  scons [scons-args] -- settings.conf [user-args]
"""

import argparse
import configparser
import csv
import os
import re
import sys
from itertools import groupby
from operator import itemgetter
from os import environ, path

from bioscons.slurm import SlurmEnvironment

from SCons.Script import (Decider, Variables, Depends, Delete)

import common

########################################################################
########################  input data  ##################################
#######################################################################

# arguments after "--" are ignored by scons
user_args = sys.argv[1 + sys.argv.index('--'):] if '--' in sys.argv else []

# we'd like to use some default values from the config file as we set
# up the command line options, but we also want to be able to specify
# the config file from the command line. This makes things a bit
# convoluted at first.
settings_default = 'settings.conf'
if user_args and path.exists(user_args[0]):
    settings = user_args[0]
elif path.exists(settings_default):
    settings = settings_default
else:
    sys.exit('A configuration file must be provided, either as '
             'the first argument after "--", or named "{}" '
             'in this directory'.format(settings_default))

conf = configparser.SafeConfigParser(allow_no_value=True)
conf.read(settings)

thisdir = path.basename(os.getcwd())
venv = conf.get('DEFAULT', 'virtualenv') or thisdir + '-env'

# Configure a virtualenv and environment
if not path.exists(venv):
    sys.exit('Please specify a virtualenv in settings.conf or '
             'create one using \'bin/bootstrap.sh\'.')
elif not ('VIRTUAL_ENV' in environ and
          environ['VIRTUAL_ENV'].endswith(path.basename(venv))):
    sys.exit('--> run \nsource {}/bin/activate'.format(venv))

# define parser and parse arguments following '--'
parser = argparse.ArgumentParser(
    description=__doc__,
    formatter_class=argparse.RawDescriptionHelpFormatter)
parser.add_argument(
    'config', help="configuration file [%(default)s]",
    nargs='*', default='settings.conf')
parser.add_argument(
    '--outdir', help='output directory [%(default)s]',
    default=conf['details'].get('outdir', 'output-details'))
parser.add_argument(
    '--nproc', type=int, default=20,
    help='number of processes for parallel tasks')

# parser.add_argument(
#     '--mock', action='store_true', default=False,
#     help='Run pipeline with a downsampled subset of input seqs')

scons_args = parser.add_argument_group('scons options')
scons_args.add_argument('--sconsign-in-outdir', action='store_true', default=False,
                        help="""store file signatures in a separate
                        .sconsign file in the output directory""")

slurm_args = parser.add_argument_group('slurm options')
slurm_args.add_argument('--use-slurm', action='store_true', default=False)
slurm_args.add_argument(
    '--slurm-account', help='provide a value for environment variable SLURM_ACCOUNT')

args = parser.parse_args(user_args)

# inputs from the configuration
input = conf['input']
refpkg = input.get('refpkg')
specimen_map = input.get('specimen_map')  # was 'seq_info'
weights = input.get('weights')
labels = input.get('labels') or None

refs = conf['refs']
ref_seqs = refs.get('ref_seqs')
ref_info = refs.get('ref_info')

# inputs from the classification pipeline
yapp_output = conf['output']['outdir']


def get_path(fname, dirname=yapp_output):
    pth = path.join(dirname, fname)
    assert path.exists(pth), f'{pth} is missing'
    print(f'--> input: {pth}')
    return pth


# TODO: define these names in the config file?
classifications = get_path('classifications.csv')
unaligned_seqs = get_path('16s.fasta')
merged_seqs = get_path('merged_16s_aln.fasta')
# dedup_info =
dedup_jplace = get_path('dedup.jplace')

singularity = conf['singularity'].get('singularity', 'singularity')
deenurp_img = conf['singularity']['deenurp']

# end input data

# check timestamps before calculating md5 checksums
Decider('MD5-timestamp')

# declare variables for the environment
vars = Variables()
vars.Add('out', None, args.outdir)
vars.Add('nproc', None, args.nproc)
vars.Add('venv', None, venv)

# Explicitly define PATH, giving preference to local executables; it's
# best to use absolute paths for non-local executables rather than add
# paths here to avoid accidental introduction of external
# dependencies.
env = SlurmEnvironment(
    ENV=dict(
        os.environ,
        PATH=':'.join(['bin', path.join(venv, 'bin'),
                       '/usr/local/bin', '/usr/bin', '/bin']),
        SLURM_ACCOUNT='fredricks_d'),
    variables=vars,
    use_cluster=args.use_slurm,
    # slurm_queue=small_queue,
    SHELL='bash',
    cwd=os.getcwd(),
    deenurp_img=('{} exec -B $cwd --pwd $cwd {}'.format(
        singularity, deenurp_img)),
)

# see http://www.scons.org/doc/HTML/scons-user/a11726.html
if args.sconsign_in_outdir:
    env.SConsignFile(None)

# start analysis

# compare OTU reps to reference sequences.
hits_uc = env.Command(
    target='$out/hits.uc',
    source=[unaligned_seqs, ref_seqs],
    action=('$deenurp_img vsearch --usearch_global ${SOURCES[0]} --db ${SOURCES[1]} '
            '--blast6out /dev/stdout '
            '--strand plus '
            '--id 0.8 '
            '--query_cov 0.9 '
            '--maxaccepts 1 '
            '> $TARGET '),
    use_cluster=False
)

hits_csv = env.Command(
    target='$out/hits.csv',
    source=hits_uc,
    action='blast2csv.py $SOURCE -o $TARGET'
)

# make a database containing blast results along with reference seq
# annotation
hits_db, = env.Command(
    target='$out/hits.db',
    source=[hits_csv, ref_info, classifications, specimen_map, weights],
    action=('rm -f $TARGET && '
            'csvsql --db sqlite:///$TARGET --table hits --insert ${SOURCES[0]} && '
            'csvsql --db sqlite:///$TARGET --table ref_info --insert ${SOURCES[1]} && '
            'csvsql --db sqlite:///$TARGET --table classif --insert ${SOURCES[2]} && '
            '(echo name,specimen; cat ${SOURCES[3]}) | '
            'csvsql --db sqlite:///$TARGET --table seq_info --insert && '
            '(echo name,name1,abundance; cat ${SOURCES[4]}) | '
            'csvsql --db sqlite:///$TARGET --table weights --insert ')
)

# summaries of all hits
for_transfer = []

allhits, = env.Command(
    target='$out/all_hits.csv',
    source=[hits_db, 'bin/allhits.sql'],
    action=('sqlite3 -header -csv ${SOURCES[0]} < ${SOURCES[1]} > $TARGET')
)
for_transfer.append(allhits)

allhits_byspecimen, = env.Command(
    target='$out/all_hits_byspecimen.csv',
    source=[hits_db, 'bin/allhits_byspecimen.sql'],
    action=('sqlite3 -header -csv ${SOURCES[0]} < ${SOURCES[1]} > $TARGET')
)
for_transfer.append(allhits_byspecimen)

# get a list of taxa
with open(str(classifications)) as f:
    keyfun = itemgetter('rank_order', 'rank', 'tax_name', 'tax_id')
    taxa = groupby(sorted(csv.DictReader(f), key=keyfun), key=keyfun)

    for (rank_order, rank, tax_name, tax_id), rows in taxa:
        safe_name = re.sub(r'[^a-zA-Z0-9]+', '_', tax_name).strip('_')

        e = env.Clone(
            safe_name=safe_name,
            out=path.join(env.subst('$out'), rank, safe_name),
            rank=rank,
            tax_id=tax_id,
        )

        # get representative seeds and reference sequences; ensure 0
        # exit status when there are seqs matching this tax_id
        aln, names, hits_csv = e.Command(
            source=[refpkg, hits_db, merged_seqs],
            target=['$out/combined.aln.fasta',
                    '$out/combined_names.csv',
                    '$out/hits.csv'],
            action=[
                ('$deenurp_img bin/get_reps.py '
                 '$SOURCES '
                 '--seqs ${TARGETS[0]} '
                 '--names ${TARGETS[1]} '
                 '--hits ${TARGETS[2]} '
                 '--rank $rank '
                 '--tax-id $tax_id '
                 '--limit 50 '),
                ("grep -q '>' ${TARGETS[0]} && "
                 '$deenurp_img seqmagick mogrify --squeeze ${TARGETS[0]} '
                 '|| true')
            ])
        Depends(hits_csv, 'bin/get_reps.py')

        # there may be no query sequence meeting filtering criteria,
        # so check first (lines starting with 'q' are query sequences)
        if names.exists() and [line for line in open(str(names)) if line.startswith('q,')]:
            placements, tog, sing = e.Command(
                target=['$out/combined.jplace',
                        '$out/combined_tog.xml',
                        '$out/combined_sing.xml'],
                source=[dedup_jplace, names],
                action=('$deenurp_img bin/filter_jplace.py $SOURCES '
                        '--placements ${TARGETS[0]} '
                        '--tog ${TARGETS[1]} '
                        '--sing ${TARGETS[2]} ')
            )
            Depends(placements, 'bin/filter_jplace.py')

            e['names_tmp'] = '$out/names.tmp'
            otu_reps, = e.Command(
                target='$out/sv_reps.fasta',
                source=[names, unaligned_seqs],
                action=[
                    ('grep -E ^q ${SOURCES[0]} | cut -f2 -d, > $names_tmp'),
                    ('$deenurp_img seqmagick convert --include-from-file $names_tmp '
                     '--ungap ${SOURCES[1]} $TARGET '),
                    Delete('$names_tmp')
                ]
            )
            for_transfer.extend([aln, hits_csv, tog, sing, otu_reps])


# write a list of files to transfer
for_transfer_txt = env.Local(
    target='$out/for_transfer.txt',
    source=for_transfer,
    action=common.list_files
)
Depends(for_transfer_txt, for_transfer)
